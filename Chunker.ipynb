{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Explanation of the Function:\n",
        "#####Input: The function chunk_sentence takes a single string argument sentence.\n",
        "#####Tokenization: It uses word_tokenize to split the sentence into words.\n",
        "#####POS Tagging: The tokens are then tagged with parts of speech using pos_tag.\n",
        "####Chunk Grammar: The grammar for chunking noun phrases (NP) is defined.\n",
        "#####Chunk Parsing: A RegexpParser object is created with the specified grammar, and the tagged sentence is parsed to create a chunk tree.\n",
        "#####Output: The function returns the chunked sentence as an nltk.Tree object."
      ],
      "metadata": {
        "id": "95MwrJXarDHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yzna1FIkx36",
        "outputId": "a1ffda0e-23a4-4669-e3e4-d2aa1e9bd587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.chunk import RegexpParser\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESvvLbaik0xv",
        "outputId": "5cd052f8-335b-4da5-8b95-614a30cc9bea"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_sentence(sentence):\n",
        "    # Tokenize the sentence\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    # Perform POS tagging\n",
        "    tagged = pos_tag(tokens)\n",
        "\n",
        "    # Define the chunk grammar\n",
        "    grammar = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "\n",
        "    # Create a chunk parser\n",
        "    chunk_parser = RegexpParser(grammar)\n",
        "\n",
        "    # Parse the sentence\n",
        "    tree = chunk_parser.parse(tagged)\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Example usage\n",
        "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
        "chunked = chunk_sentence(sentence)\n",
        "print(chunked)\n",
        "chunked.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy9LrdcvlCtl",
        "outputId": "8a7f4d47-e00d-4881-ca2b-359aa83945b6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  The/DT\n",
            "  quick/JJ\n",
            "  brown/NN\n",
            "  fox/NN\n",
            "  jumps/VBZ\n",
            "  over/IN\n",
            "  the/DT\n",
            "  lazy/JJ\n",
            "  dog/NN)\n",
            "                                    S                                  \n",
            "   _________________________________|______________________________     \n",
            "The/DT quick/JJ brown/NN fox/NN jumps/VBZ over/IN the/DT lazy/JJ dog/NN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AN7-27adlPBU"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}