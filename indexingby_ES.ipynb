{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#using elastic search\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m1bLdYYoJZjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#01 Install and set up Elasticsearch"
      ],
      "metadata": {
        "id": "y3UDnuz1Jnzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install elasticsearch\n",
        "!wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.1-linux-x86_64.tar.gz\n",
        "!tar -xzf elasticsearch-7.10.1-linux-x86_64.tar.gz\n",
        "!chown -R daemon:daemon elasticsearch-7.10.1\n",
        "!elasticsearch-7.10.1/bin/elasticsearch -d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU_cRrowJlw7",
        "outputId": "db49e87e-a2da-4cbf-e7fd-31438e83e53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.14.0)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.13 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.13.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.6.2)\n",
            "--2024-06-13 10:08:16--  https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.1-linux-x86_64.tar.gz\n",
            "Resolving artifacts.elastic.co (artifacts.elastic.co)... 34.120.127.130, 2600:1901:0:1d7::\n",
            "Connecting to artifacts.elastic.co (artifacts.elastic.co)|34.120.127.130|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 318801277 (304M) [application/x-gzip]\n",
            "Saving to: ‘elasticsearch-7.10.1-linux-x86_64.tar.gz’\n",
            "\n",
            "elasticsearch-7.10. 100%[===================>] 304.03M  28.3MB/s    in 9.4s    \n",
            "\n",
            "2024-06-13 10:08:26 (32.5 MB/s) - ‘elasticsearch-7.10.1-linux-x86_64.tar.gz’ saved [318801277/318801277]\n",
            "\n",
            "uncaught exception in thread [main]\n",
            "java.lang.RuntimeException: can not run elasticsearch as root\n",
            "\tat org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:111)\n",
            "\tat org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:178)\n",
            "\tat org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:393)\n",
            "\tat org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:170)\n",
            "\tat org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:161)\n",
            "\tat org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86)\n",
            "\tat org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:127)\n",
            "\tat org.elasticsearch.cli.Command.main(Command.java:90)\n",
            "\tat org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:126)\n",
            "\tat org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92)\n",
            "For complete error details, refer to the log at /content/elasticsearch-7.10.1/logs/elasticsearch.log\n",
            "2024-06-13 10:08:46,494897 UTC [9454] INFO  Main.cc@103 Parent process died - ML controller exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from elasticsearch import Elasticsearch\n",
        "from elasticsearch.helpers import bulk\n",
        "import time\n"
      ],
      "metadata": {
        "id": "ccCwyjZFJ8yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Elasticsearch\n",
        "es = Elasticsearch(['http://localhost:9200'])\n",
        "# Wait for Elasticsearch to start\n",
        "time.sleep(30)"
      ],
      "metadata": {
        "id": "Ol2dPSZ4KB7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = [np.random.rand(128) for _ in range(1000)]\n",
        "\n",
        "# Define the index name\n",
        "index_name = \"embeddings\"\n",
        "\n",
        "# Define the mapping for the index\n",
        "mapping = {\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"embedding\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": 128\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "yLmbqDx56x_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the index\n",
        "if not es.indices.exists(index=index_name):\n",
        "    es.indices.create(index=index_name, body=mapping)\n",
        "\n",
        "def generate_actions(embeddings):\n",
        "    for i, embedding in enumerate(embeddings):\n",
        "        yield {\n",
        "            \"_index\": index_name,\n",
        "            \"_id\": i,\n",
        "            \"_source\": {\n",
        "                \"embedding\": embedding.tolist()\n",
        "            }\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "K2VhOh68KRcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use bulk indexing for efficiency\n",
        "bulk(es, generate_actions(embeddings))\n",
        "\n",
        "# Define the query embedding\n",
        "query_embedding = np.random.rand(128)\n",
        "# Create the query\n",
        "query = {\n",
        "    \"query\": {\n",
        "        \"script_score\": {\n",
        "            \"query\": {\n",
        "                \"match_all\": {}\n",
        "            },\n",
        "            \"script\": {\n",
        "                \"source\": \"cosineSimilarity(params.query_embedding, 'embedding') + 1.0\",\n",
        "                \"params\": {\n",
        "                    \"query_embedding\": query_embedding.tolist()\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "g033SudRKUoQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the search\n",
        "response = es.search(index=index_name, body=query)"
      ],
      "metadata": {
        "id": "qnsBMAHSKg4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = response[\"hits\"][\"hits\"]\n",
        "nearest_neighbors = [(hit[\"_id\"], hit[\"_score\"]) for hit in results]\n",
        "\n",
        "print(\"Nearest Neighbors:\", nearest_neighbors)"
      ],
      "metadata": {
        "id": "uj5mf6htKdZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl http://localhost:9200/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqxrVEP7AHEX",
        "outputId": "b41e8878-8207-4c59-92f3-bd829de4cf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (7) Failed to connect to localhost port 9200 after 0 ms: Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch()"
      ],
      "metadata": {
        "id": "N0GAoyna8o8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create an Index in Elasticsearch"
      ],
      "metadata": {
        "id": "imqKj0bzFs9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_index(index_name=\"sbert_embeddings\"):\n",
        "    settings = {\n",
        "        \"settings\": {\n",
        "            \"number_of_shards\": 1,\n",
        "            \"number_of_replicas\": 0\n",
        "        },\n",
        "        \"mappings\": {\n",
        "            \"properties\": {\n",
        "                \"text\": {\"type\": \"text\"},\n",
        "                \"embedding\": {\"type\": \"dense_vector\", \"dims\": 768}\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    es.indices.create(index=index_name, body=settings, ignore=400)\n",
        "    print(f\"Index {index_name} created.\")\n"
      ],
      "metadata": {
        "id": "JuXHaPme8q69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Index Documents"
      ],
      "metadata": {
        "id": "F2MJ1lIQF70n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def index_documents(documents, embeddings, index_name=\"sbert_embeddings\"):\n",
        "    actions = [\n",
        "        {\n",
        "            \"_index\": index_name,\n",
        "            \"_source\": {\n",
        "                \"text\": doc,\n",
        "                \"embedding\": embedding.tolist()\n",
        "            }\n",
        "        }\n",
        "        for doc, embedding in zip(documents, embeddings)\n",
        "    ]\n",
        "    helpers.bulk(es, actions)\n",
        "    print(\"Documents indexed.\")\n"
      ],
      "metadata": {
        "id": "IKFMkXc68tU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Query by Embedding"
      ],
      "metadata": {
        "id": "4FR0SlrAF-TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_by_embedding(query_embedding, index_name=\"sbert_embeddings\", top_n=10):\n",
        "    script_query = {\n",
        "        \"script_score\": {\n",
        "            \"query\": {\"match_all\": {}},\n",
        "            \"script\": {\n",
        "                \"source\": \"cosineSimilarity(params.query_embedding, 'embedding') + 1.0\",\n",
        "                \"params\": {\"query_embedding\": query_embedding}\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    response = es.search(index=index_name, body={\"query\": script_query, \"size\": top_n})\n",
        "    return response['hits']['hits']\n"
      ],
      "metadata": {
        "id": "0oMMuCXM8vnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example"
      ],
      "metadata": {
        "id": "iv-ADKXo-2ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"Hello world\",\n",
        "    \"Elasticsearch is a search engine based on Lucene\",\n",
        "    \"Annoy is a C++ library with Python bindings\",\n",
        "    \"SBERT is a modification of the pretrained BERT network\"\n",
        "]\n",
        "\n",
        "#embeddings generated by SBERT\n",
        "embeddings = np.random.rand(len(documents), 768)\n"
      ],
      "metadata": {
        "id": "aJbSoGEL8x8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_index(index_name=\"sbert_embeddings\")\n",
        "index_documents(documents, embeddings, index_name=\"sbert_embeddings\")\n"
      ],
      "metadata": {
        "id": "uXkAhmyG-Q2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query embedding\n",
        "query_text = \"search engine technology\"\n",
        "query_embedding = np.random.rand(768)  # In practice, generate this using SBERT\n",
        "\n",
        "\n",
        "search_results = search_by_embedding(query_embedding, index_name=\"sbert_embeddings\", top_n=3)\n",
        "\n",
        "for result in search_results:\n",
        "    print(f\"Document: {result['_source']['text']}, Score: {result['_score']}\")\n"
      ],
      "metadata": {
        "id": "9vZCoxav-S_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize SBERT model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "documents = [\n",
        "    \"Hello world\",\n",
        "    \"Elasticsearch is a search engine based on Lucene\",\n",
        "    \"Annoy is a C++ library with Python bindings\",\n",
        "    \"SBERT is a modification of the pretrained BERT network\"\n",
        "]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = np.array([model.encode(doc) for doc in documents])\n",
        "\n",
        "# Create Elasticsearch index\n",
        "create_index(index_name=\"sbert_embeddings\")\n",
        "\n",
        "# Index documents with their embeddings\n",
        "index_documents(documents, embeddings, index_name=\"sbert_embeddings\")\n",
        "\n",
        "# Query for similar documents\n",
        "query_text = \"search engine technology\"\n",
        "query_embedding = model.encode(query_text)\n",
        "search_results = search_by_embedding(query_embedding, index_name=\"sbert_embeddings\", top_n=3)\n",
        "\n",
        "print(\"Search Results:\")\n",
        "for result in search_results:\n",
        "    print(f\"Document: {result['_source']['text']}, Score: {result['_score']}\")\n"
      ],
      "metadata": {
        "id": "wV6BwRCs-yNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}